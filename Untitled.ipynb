{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12227af5-05a2-42a8-bc64-7965bf751038",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Callable\n",
    "import SimpleITK as sitk\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from pathlib import Path\n",
    "from monai import transforms as mt\n",
    "import matplotlib.pyplot as plt\n",
    "from monai.data import CacheDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c5a79f-e5b8-4d01-8975-e6f85a7afb51",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "415b4d59-f283-44a0-8b1f-19b22ee307db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(\n",
    "    image: torch.Tensor,\n",
    "    label: torch.Tensor | None = None,\n",
    "    crop_size: tuple[int, ...] = (28, 28, 28)\n",
    ") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    \n",
    "    # Normalize the image (Z-score normalization)\n",
    "    image = (image - image.mean() ) / image.std()\n",
    "    \n",
    "    # Add a channel dimension to the image\n",
    "    image = image.unsqueeze(0)\n",
    "\n",
    "    # Random crop\n",
    "    crop_origin = [0, 0, 0]\n",
    "    for dim in range(3):  # Remember, image.shape = [Ch, X, Y, Z ]\n",
    "        max_value = image.shape[dim+1] - crop_size[dim]\n",
    "        crop_origin[dim] = torch.randint(0, max_value, (1,)).item()\n",
    "        \n",
    "    image = image[\n",
    "        :,\n",
    "        crop_origin[0]:crop_origin[0] + crop_size[0],\n",
    "        crop_origin[1]:crop_origin[1] + crop_size[1],\n",
    "        crop_origin[2]:crop_origin[2] + crop_size[2],\n",
    "    ]\n",
    "    \n",
    "    # Add a channel dimension to the label\n",
    "    if label is not None:\n",
    "        label = label.unsqueeze(0)\n",
    "\n",
    "        label = label[\n",
    "            :,\n",
    "            crop_origin[0]:crop_origin[0] + crop_size[0],\n",
    "            crop_origin[1]:crop_origin[1] + crop_size[1],\n",
    "            crop_origin[2]:crop_origin[2] + crop_size[2],\n",
    "        ]\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96e35ad-99aa-4080-8138-59d8e30b0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_samples(root: Path, is_test: bool = False) -> list[dict[str, Path]]:\n",
    "    \"\"\"\n",
    "    Collects the samples from the Medical Decathlon dataset.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    root : Path\n",
    "        The root directory of the dataset.\n",
    "    is_test : bool\n",
    "        Whether to collect the test set or the training set.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list[dict[str, Path]]\n",
    "        A list of dictionaries containing the image and label paths.\n",
    "    \"\"\"\n",
    "  \n",
    "   # if test_set:\n",
    "    #    image_dir = root / \"imagesTs\"\n",
    "   #     label_dir = None\n",
    "   # else:\n",
    "    #    image_dir = root / \"imagesTr\"\n",
    "     #   label_dir = root / \"labelsTr\"\n",
    "    #samples = []\n",
    "    samples = []\n",
    "    # Iterate through each subject directory\n",
    "    for subject_dir in root.iterdir():\n",
    "        if subject_dir.is_dir():  # Check if it's a directory\n",
    "            flair_path = subject_dir / \"FLAIR.nii.gz\"\n",
    "            t1_path = subject_dir / \"T1.nii.gz\"\n",
    "            WMH_path = subject_dir / \"wmh.nii.gz\"\n",
    "            \n",
    "            # Check if all required files exist\n",
    "            if flair_path.exists() and t1_path.exists() and WMH_path.exists():\n",
    "                sample = {\n",
    "                    \"flair\": flair_path,\n",
    "                    \"t1\": t1_path,\n",
    "                    \"WMH\": WMH_path\n",
    "                }\n",
    "                samples.append(sample)\n",
    "            else:\n",
    "                print(f\"Missing files in {subject_dir}: \"\n",
    "                      f\"{'FLAIR' if not flair_path.exists() else ''} \"\n",
    "                      f\"{'T1' if not t1_path.exists() else ''} \"\n",
    "                      f\"{'wmh' if not WMH_path.exists() else ''}\")\n",
    "\n",
    "    return samples\n",
    "\n",
    "class MedicalDecathlonDataset(Dataset):\n",
    "    def __init__(self, samples: list[tuple[Path, ...]], test: bool = False) -> None:\n",
    "        self.samples = samples \n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> tuple[torch.Tensor, torch.Tensor] | torch.Tensor:\n",
    "        image_path, label_path = self.samples[idx]\n",
    "        \n",
    "        image = sitk.ReadImage(image_path)\n",
    "        image_array = sitk.GetArrayFromImage(image)\n",
    "        image = torch.tensor(image_array,dtype=torch.float32)  # Convert image to PyTorch tensor and cast it to float\n",
    "\n",
    "        if label_path is None:\n",
    "           image, _ = preprocess(image)\n",
    "           return image\n",
    "\n",
    "        label = sitk.ReadImage(label_path)\n",
    "        label_array = sitk.GetArrayFromImage(label)\n",
    "        label = torch.tensor(label_array,dtype=torch.float32)\n",
    "\n",
    "        return preprocess(image, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c06f37-e880-4b21-bf55-ee41d4de7991",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = mt.Compose([\n",
    "    mt.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "    mt.EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "    mt.NormalizeIntensityd(keys=[\"image\"]),\n",
    "    mt.RandSpatialCropd(keys=[\"image\", \"label\"], roi_size=[28, 28, 28]),\n",
    "    # You can add more transforms here! See\n",
    "    # https://docs.monai.io/en/stable/transforms.html#dictionary-transforms\n",
    "])\n",
    "\n",
    "val_transforms = mt.Compose([\n",
    "    mt.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "    mt.EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
    "    mt.NormalizeIntensityd(keys=[\"image\"]),\n",
    "])\n",
    "\n",
    "root = Path(r\"C:/Users/20213084/OneDrive - TU Eindhoven/Desktop/8UU22/Group project/WMH/WMH/Utrecht/0\").resolve()\n",
    "samples = collect_samples(root)\n",
    "\n",
    "train_samples = samples[:int(len(samples) * 0.8)]\n",
    "val_samples = samples[int(len(samples) * 0.8):]\n",
    "\n",
    "# You might get an error here, make sure you install the required extra dependencies\n",
    "# https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
    "train_ds = CacheDataset(data=train_samples, transform= train_transforms)\n",
    "val_ds   = CacheDataset(data=val_samples,   transform= val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7d2556-1e1b-42a7-af7b-9726b48ee43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nifti_image(image_path: Path):\n",
    "    \"\"\"Load a NIfTI image using SimpleITK.\"\"\"\n",
    "    image = sitk.ReadImage(str(image_path))\n",
    "    return sitk.GetArrayFromImage(image)  # Convert to NumPy array\n",
    "\n",
    "def visualize_sample(sample):\n",
    "    \"\"\"Visualize FLAIR, T1, and WMH images from a sample.\"\"\"\n",
    "    flair_image = load_nifti_image(sample['flair'])\n",
    "    t1_image = load_nifti_image(sample['t1'])\n",
    "    label_image = load_nifti_image(sample['WMH'])\n",
    "\n",
    "    # Select a slice to visualize (e.g., the middle slice)\n",
    "    slice_index = flair_image.shape[0] // 2\n",
    "\n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "    \n",
    "    # FLAIR Image\n",
    "    axes[0].imshow(flair_image[slice_index, :, :], cmap='gray')\n",
    "    axes[0].set_title('FLAIR Image')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # T1 Image\n",
    "    axes[1].imshow(t1_image[slice_index, :, :], cmap='gray')\n",
    "    axes[1].set_title('T1 Image')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # WMH Label\n",
    "    axes[2].imshow(label_image[slice_index, :, :], cmap='gray')\n",
    "    axes[2].set_title('WMH')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "root = Path(r\"./WMH/WMH/Amsterdam\").resolve()\n",
    "root2 = Path(r\"./WMH/WMH/Singapore\").resolve()\n",
    "root3 = Path(r\"./WMH/WMH/Utrecht\").resolve()\n",
    "samples = collect_samples(root) + collect_samples(root2) + collect_samples(root3)\n",
    "\n",
    "# Visualize the first sample if available\n",
    "if samples:\n",
    "    visualize_sample(samples[0])  # Visualize the first sample\n",
    "else:\n",
    "    print(\"No samples found to visualize.\")\n",
    "len(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0fed3f-43ce-4730-b7b1-c868a4cdbfb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
