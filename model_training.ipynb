{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.losses import DiceLoss\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTraining():\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_epochs: int,\n",
    "        batch_size: int,\n",
    "        learning_rate: float,\n",
    "        loss_fn: function,\n",
    "        samples: list\n",
    "    ) -> None:\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model = UNet(n_dims=2, in_channels=1, out_channels=1, depth=3).to(self.device)\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=learning_rate)\n",
    "        self.train_ds, self.train_dl, self.val_ds, self.val_dl = self._split_samples(samples)\n",
    "    \n",
    "    def run_training_loop(self):\n",
    "        for epoch in (prog_bar := tqdm(range(self.n_epochs), desc=\"Training\", unit=\"epoch\", total=self.n_epochs, position=0)):\n",
    "            prog_bar.set_description(f\"Training Loop\")\n",
    "            train_losses = self._loop_train()\n",
    "            prog_bar.set_postfix({\"Training loss\": sum(train_losses) / len(train_losses)})\n",
    "            prog_bar.set_description(f\"Validation Loop\")\n",
    "            val_losses = self._loop_validate()\n",
    "            prog_bar.set_postfix({\"Training loss\": sum(train_losses) / len(train_losses), \"Validation loss\": sum(val_losses) / len(val_losses)})\n",
    "        \n",
    "    def _loop_train(self):\n",
    "        self.model.train()\n",
    "        train_losses = []\n",
    "\n",
    "        for i, (image, label) in tqdm(enumerate(self.train_dl), total=len(self.train_dl), desc=\"Training\", unit=\"batch\", position=1, leave=False):\n",
    "            \n",
    "            image, label = image.to(self.device), label.to(self.device)\n",
    "\n",
    "            self.optimizer.zero_grad() # Clear gradients\n",
    "            output = self.model(...) # Model forward pass\n",
    "            loss = loss_fn(output, label)  # Compute loss\n",
    "            loss.backward()  # Backpropagate loss\n",
    "            self.optimizer.step()  # Update model weights\n",
    "\n",
    "            train_losses.append(loss.item()) # Append training loss for this batch\n",
    "\n",
    "        return train_losses\n",
    "\n",
    "    def _loop_validate(self):\n",
    "        self.model.eval() # We set the model in evaluation mode\n",
    "        val_losses = []\n",
    "        for i, (image, label) in tqdm(enumerate(self.val_dl), total=len(self.val_dl), desc=\"Validation\", unit=\"batch\", position=1, leave=False):\n",
    "            image, label = image.to(self.device), label.to(self.device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = self.model(image)\n",
    "                loss = loss_fn(output, label)\n",
    "            \n",
    "            val_losses.append(loss.item())\n",
    "\n",
    "        return val_losses\n",
    "\n",
    "    def _split_samples(self, samples): #TODO - adjust this function to our data\n",
    "        train_samples = samples[0 : int(len(samples) * 0.8)]\n",
    "        val_samples = samples[int(len(samples) * 0.8): ]\n",
    "\n",
    "        train_ds = MedicalDecathlonDataset(train_samples) #TODO - change to our own dataset class\n",
    "        train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True) #TODO - change to our DataLoader class\n",
    "\n",
    "        val_ds = MedicalDecathlonDataset(val_samples) #TODO - change to our own dataset class\n",
    "        val_dl = DataLoader(val_ds, batch_size=batch_size, shuffle=False) #TODO - change to our DataLoader class\n",
    "        return train_ds, train_dl, val_ds, val_dl\n",
    "\n",
    "\n",
    "loss_functions = [nn.BCEWithLogitsLoss()] #TODO - add different loss functions to evaluate\n",
    "for loss_fn in loss_functions:\n",
    "    Model_training = ModelTraining(\n",
    "        n_epochs = 10,\n",
    "        batch_size = 4,\n",
    "        learning_rate = 1e-3,\n",
    "        loss_fn = loss_fn\n",
    "        )\n",
    "\n",
    "    Model_training.run_training_loop()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
